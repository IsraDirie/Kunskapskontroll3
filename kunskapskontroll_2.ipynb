{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DATA24HEL_DBT25/Databastyper\n",
        "# Kunskapskontroll 2\n",
        "\n",
        "Gör kurserna i den här samlingen: [https://learn.microsoft.com/en-us/collections/3140s6twkorq6z?&sharingId=A70F2DF98827F6CC](https://learn.microsoft.com/en-us/collections/3140s6twkorq6z?&sharingId=A70F2DF98827F6CC)\n",
        "\n",
        "### OBS! Du behöver __inte__ göra *exercises*!\n",
        "\n",
        "Svara på frågorna nedan. Eftersom kurserna är på engelska har jag skrivit även frågorna på engelska. Det går bra att svara på svenska eller engelska.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Microsoft Azure Data Fundamentals: Explore core data concepts\n",
        "### Explore core data concepts\n",
        "#### Identify data formats\n",
        "\n",
        "❓ What data format is often represented as JSON?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"JSON is just one of many ways in which semi-structured data can be represented. The point here is not to provide a detailed examination of JSON syntax, but rather to illustrate the flexible nature of semi-structured data representations\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What data format is represented in a tabular format?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Structured data is data that adheres to a fixed schema, so all of the data has the same fields or properties. Most commonly, the schema for structured data entities is tabular - in other words, the data is represented in one or more tables that consist of rows to represent each instance of a data entity, and columns to represent attributes of the entity. For example, the following image shows tabular data representations for Customer and Product entities\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the data format of images, pdf-documents and binary files called?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"unstructured data\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Give an example of an optimized file format for structured and semi-structured data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"While human-readable formats for structured and semi-structured data can be useful, they're typically not optimized for storage space or processing. Over time, some specialized file formats that enable compression, indexing, and efficient storage and processing have been developed.\n",
        "\n",
        "Some common optimized file formats you might see include Avro, ORC, and Parquet:\n",
        "\n",
        "Avro is a row-based format. It was created by Apache. Each record contains a header that describes the structure of the data in the record. This header is stored as JSON. The data is stored as binary information. An application uses the information in the header to parse the binary data and extract the fields it contains. Avro is a good format for compressing data and minimizing storage and network bandwidth requirements.\n",
        "\n",
        "ORC (Optimized Row Columnar format) organizes data into columns rather than rows. It was developed by HortonWorks for optimizing read and write operations in Apache Hive (Hive is a data warehouse system that supports fast data summarization and querying over large datasets). An ORC file contains stripes of data. Each stripe holds the data for a column or set of columns. A stripe contains an index into the rows in the stripe, the data for each row, and a footer that holds statistical information (count, sum, max, min, and so on) for each column.\n",
        "\n",
        "Parquet is another columnar data format. It was created by Cloudera and X. A Parquet file contains row groups. Data for each column is stored together in the same row group. Each row group contains one or more chunks of data. A Parquet file includes metadata that describes the set of rows found in each chunk. An application can use this metadata to quickly locate the correct chunk for a given set of rows, and retrieve the data in the specified columns for these rows. Parquet specializes in storing and processing nested data types efficiently. It supports very efficient compression and encoding schemes\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Explore transactional data processing\n",
        "❓ What are OLTP systems designed for?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Transactional systems are often high-volume, sometimes handling many millions of transactions in a single day. The data being processed has to be accessible very quickly. The work performed by transactional systems is often referred to as Online Transactional Processing (OLTP).\n",
        "OLTP solutions rely on a database system in which data storage is optimized for both read and write operations in order to support transactional workloads in which data records are created, retrieved, updated, and deleted (often referred to as CRUD operations). These operations are applied transactionally, in a way that ensures the integrity of the data stored in the database. To accomplish this, OLTP systems enforce transactions that support so-called ACID semantics\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Explore analytical data processing\n",
        "❓ What are OLAP systems designed for?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"An OLAP model is an aggregated type of data storage that is optimized for analytical workloads. Data aggregations are across dimensions at different levels, enabling you to drill up/down to view aggregations at multiple hierarchical levels; for example to find total sales by region, by city, or for an individual address. Because OLAP data is pre-aggregated, queries to return the summaries it contains can be run quickly.\n",
        "\n",
        "Different types of user might perform data analytical work at different stages of the overall architecture. For example:\n",
        "\n",
        "Data scientists might work directly with data files in a data lake to explore and model data.\n",
        "Data Analysts might query tables directly in the data warehouse to produce complex reports and visualizations.\n",
        "Business users might consume pre-aggregated data in an analytical model in the form of reports or dashboards\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore data roles and services\n",
        "#### Explore job roles in the world of data\n",
        "\n",
        "❓Describe some of the responsibilities of a:\n",
        "\n",
        "* Database Administrator\n",
        "* Data Engineer\n",
        "* Data Analyst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Database administrators manage databases, assigning permissions to users, storing backup copies of data, and restoring data in the event of a failure.\n",
        "Data engineers manage infrastructure and processes for data integration across the organization, applying data cleaning routines, identifying data governance rules, and implementing pipelines to transfer and transform data between systems.\n",
        "Data analysts explore and analyze data to create visualizations and charts that enable organizations to make informed decisions\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Microsoft Azure Data Fundamentals: Explore relational data in Azure\n",
        "### Explore fundamental relational data concepts\n",
        "\n",
        "❓ How is relational data commonly organized?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"The relational database model was designed to solve the problem of multiple arbitrary data structures. The relational model provides a standard way of representing and querying data that can be used by any application. One of the key advantages of the relational database model is its use of tables, which are an intuitive, efficient, and flexible way to store and access structured information.\n",
        "\n",
        "The simple yet powerful relational model is used by organizations of all types and sizes for a broad variety of information management needs. Relational databases are used to track inventories, process ecommerce transactions, manage huge amounts of mission-critical customer information, and much more. A relational database is useful for storing any information containing related data elements that must be organized in a rules-based, consistent structure\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What are the main reasons for normalizing relational data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Normalization is a term used by database professionals for a schema design process that minimizes data duplication and enforces data integrity.\n",
        "\n",
        "While there are many complex rules that define the process of refactoring data into various levels (or forms) of normalization, a simple definition for practical purposes is:\n",
        "\n",
        "Separate each entity into its own table.\n",
        "Separate each discrete attribute into its own column.\n",
        "Uniquely identify each entity instance (row) using a primary key.\n",
        "Use foreign key columns to link related entities.\n",
        "To understand the core principles of normalization, suppose the following table represents a spreadsheet that a company uses to track its sales\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore relational database services in Azure\n",
        "\n",
        "❓ Which of the Azure SQL services requires you to manage configuration, backups, and other maintenance tasks yourself?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Azure SQL Database is a PaaS offering from Microsoft. You create a managed database server in the cloud, and then deploy your databases on this server.\n",
        "\n",
        "Single Database This option enables you to quickly set up and run a single SQL Server database. You create and run a database server in the cloud, and you access your database through this server. Microsoft manages the server, so all you have to do is configure the database, create your tables, and populate them with your data. You can scale the database if you need more storage space, memory, or processing power. By default, resources are preallocated, and you're charged per hour for the resources you've requested. You can also specify a serverless configuration. In this configuration, Microsoft creates its own server, which might be shared by databases belonging to other Azure subscribers. Microsoft ensures the privacy of your database. Your database automatically scales and resources are allocated or deallocated as required \"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Microsoft Azure Data Fundamentals: Explore non-relational data in Azure\n",
        "### Explore Azure blob storage\n",
        "\n",
        "❓ What are the three types of blob that Azure Blob Storage supports?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Block blobs, Page blobs, Append blobs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore fundamentals of Azure Cosmos DB\n",
        "#### Describe Azure Cosmos DB\n",
        "\n",
        "❓ Which data storage scenarios are Azure Cosmos DB suitable for? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:\" IoT and telematics, Retail and marketing, Gaming, Web and mobile applications\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Identify Azure Cosmos DB API\n",
        "\n",
        "❓ With Azure Cosmos DB for NoSQL you can use SQL syntax to make queries to a NoSQL database, but how are the results formatted?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Azure Cosmos DB for NoSQL is Microsoft’s native non-relational service for working with the document data model. It manages data in JSON document format, and despite being a NoSQL data storage solution, uses SQL syntax to work with the data\".\n",
        "\n",
        "A SQL query for an Azure Cosmos DB database containing customer data might look similar to this:\n",
        "\n",
        "SQL\n",
        "\n",
        "Copy\n",
        "SELECT *\n",
        "FROM customers c\n",
        "WHERE c.id = \"joe@litware.com\"\n",
        "\n",
        "The result of this query consists of one or more JSON documents, as shown here:\n",
        "\n",
        "JSON\n",
        "\n",
        "Copy\n",
        "{\n",
        "   \"id\": \"joe@litware.com\",\n",
        "   \"name\": \"Joe Jones\",\n",
        "   \"address\": {\n",
        "        \"street\": \"1 Main St.\",\n",
        "        \"city\": \"Seattle\"\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Explore fundamentals of large-scale analytics\n",
        "### Explore analytical data stores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "❓ What kind of analytical data store should you choose when you have structured data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"A data warehouse is a great choice when you have transactional data that can be organized into a structured schema of tables, and you want to use SQL to query them\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of analytical data store should you choose when you have a mix of structured, semi-structured and unstructured data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Data lakes are great for supporting a mix of structured, semi-structured, and even unstructured data that you want to analyze without the need for schema enforcement when the data is written to the store\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is a hybrid data store that combines features of data lakes and data warehouses called?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"You can use a hybrid approach that combines features of data lakes and data warehouses in a data lakehouse\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Store Data in Azure\n",
        "### Choose a data storage apporach in Azure\n",
        "#### Classify your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ How is business data classified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Business analysts want to implement business intelligence to perform inventory pipeline evaluations and sales data reviews. To perform these operations, data from multiple months needs to be aggregated and then queried. Because of the need to aggregate similar data, this data must be structured, so that one month can be compared to the next.\n",
        "\n",
        "The classification for business data is structured\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "❓ How is data for a product catalog classified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Product catalog data for an online retail business is semi-structured in nature. Each product has a product SKU, a description, a quantity, a price, size options, color options, a photo, and possibly a video\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ How is data representing photos and videos classified?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"The photos and videos displayed on product pages are unstructured data. Although the media file might contain metadata, the body of the media file is unstructured.\n",
        "\n",
        "The data classification for photos and videos is unstructured\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Group multiple operations in a transaction\n",
        "\n",
        "❓ What is ACID?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"ACID is an acronym for atomicity, consistency, isolation, and durability\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which of the three datasets (product catalog, photos and videos, business data) is transactional?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Product catalog data should be stored in a transactional database\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose a storage solution in Azure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the recommended service for a semi-structured dataset that needs a high number of both read and write operations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Software developers use data serialization languages to write data stored in memory to a file, which can then be sent to another system, parsed, and read. The sender and receiver don't need to know details about the other system. Both systems can understand the data if using the same serialization language   är inte fixat \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the recommended service for a structured dataset that will be used for analytical purposes only?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: Business analysts want to implement business intelligence to perform inventory pipeline evaluations and sales data reviews. To perform these operations, data from multiple months needs to be aggregated and then queried. Because of the need to aggregate similar data, this data must be structured, so that one month can be compared to the next.\n",
        "\n",
        "The classification for business data is structured.  ÄR inte fixat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an Azure Storage Account\n",
        "#### Decide how many storage accounts you need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the difference between Hot and Cold access tiers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"In Azure Blob Storage, you can also move images from the hot storage tier to the cool storage tier or archive storage tier. This helps reduce costs and focus throughput on the most frequently viewed images and videos\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose your account settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ When creating an Azure Storage Account, which deployment model should you choose?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: A deployment model is the system Azure uses to organize your resources. The model defines the API that you use to create, configure, and manage those resources. Azure provides two deployment models, Resource Manager and Classic. Resource Manager is the current model that uses the Azure Resource Manager API. The Classic model, which is currently being retired, was a legacy offering that used the classic deployment model.\n",
        "\n",
        "Most Azure resources only work with Resource Manager, which makes it easy to decide which model to choose. However, storage accounts, virtual machines, and virtual networks support both, so you must choose one or the other when you create your storage account.  then är inte fixat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose an account creation tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ The most commonly used account creation tool is the Azure Portal. Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:  \"The Azure portal provides a GUI with explanations for each setting, which makes it easy to use and helpful for learning about the options\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Secure your Azure Storage account\n",
        "#### Explore Azure Storage security features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ How do you disable encryption at rest?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"All data written to Azure Storage is automatically encrypted by Storage Service Encryption (SSE) with a 256-bit Advanced Encryption Standard (AES) cipher, and is FIPS 140-2 compliant. SSE automatically encrypts data when writing it to Azure Storage. When you read data from Azure Storage, Azure Storage decrypts the data before returning it. This process incurs no additional charges and doesn't degrade performance. It can't be disabled\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What happens if you require *secure transfer* for your storage account?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Keep your data secure by enabling transport-level security between Azure and the client. Always use HTTPS to secure communication over the public internet. When you call the REST APIs to access objects in storage accounts, you can enforce the use of HTTPS by requiring secure transfer for the storage account. After you enable secure transfer, connections that use HTTP will be refused. This flag will also enforce secure transfer over SMB by requiring SMB 3.0 for all file share mounts\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is CORS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"CORS uses HTTP headers so that a web application at one domain can access resources from a server at a different domain. By using CORS, web apps ensure that they load only authorized content from authorized sources.CORS support is an optional flag you can enable on Storage accounts. The flag adds the appropriate headers when you use HTTP GET requests to retrieve resources from the Storage account\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which Azure service can you use to audit accesses to your data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Auditing is another part of controlling access. You can audit Azure Storage access by using the built-in Storage Analytics service.\n",
        "\n",
        "Storage Analytics logs every operation in real time, and you can search the Storage Analytics logs for specific requests. You can filter based on the authentication mechanism, the success of the operation, or the resource that was accessed\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Understand storage account keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which authentication option is the best for Blob and Queue storage?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Azure Storage accounts can create authorized apps in Active Directory to control access to the data in blobs and queues. This authentication approach is the best solution for apps that use Blob storage or Queue storage\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Understand shared access signatures (SAS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What are the two levels of SAS?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"As a best practice, you shouldn't share storage account keys with external third-party applications. If these apps need access to your data, you'll need to secure their connections without using storage account keys.\n",
        "\n",
        "For untrusted clients, use a shared access signature (SAS). A SAS is a string that contains a security token that can be attached to a URI. You can use a SAS to delegate access to storage objects and specify constraints, such as the permissions and the time range of access.\n",
        "\n",
        "You can give a customer a SAS token, for example, so they can upload pictures to a file system in Blob storage. Separately, you can give a web app permission to read those pictures. In both cases, you allow only the access that the application needs to do the task.\n",
        "\n",
        "You can use a service-level SAS to allow access to specific resources in a storage account. You'd use this type of SAS, for example, to allow an app to retrieve a list of files in a file system, or to download a file.\n",
        "\n",
        "Use an account-level SAS to allow access to anything that a service-level SAS can allow, plus additional resources and abilities. For example, you can use an account-level SAS to allow the ability to create file systems\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Control network access to your storage account"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What must you do before you change the default network access action from *grant* to *deny*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"By default, storage accounts accept connections from clients on any network. To limit access to selected networks, you must first change the default action. You can restrict access to specific IP addresses, ranges, or virtual networks\n",
        "\n",
        "Changing network rules can affect your application's ability to connect to Azure Storage. If you set the default network rule to deny, you'll block all access to the data unless specific network rules grant access. Before you change the default rule to deny access, be sure to use network rules to grant access to any allowed networks.\n",
        "\n",
        "You can manage default network access rules for storage accounts through the Azure portal, PowerShell, or the Azure CLI.\n",
        "\n",
        "Follow these steps to change default network access in the Azure portal.\n",
        "\n",
        "Go to the storage account you want to secure.\n",
        "\n",
        "Select Networking in the left-hand pane.\n",
        "\n",
        "To restrict access to only selected networks and IPs, select Enabled from selected virtual networks and IP addresses. To enable public network access for all networks, including the internet, select Enabled from all networks.\n",
        "\n",
        "To apply your changes, select Save\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Store application data with Azure Blob Storage\n",
        "#### What are blobs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of data can't be stored as a blob?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:  \"Blobs aren't efficient for structured data that needs to be queried frequently. They have higher latency than memory and local disks. They don't have the indexing features that make databases efficient at running queries\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of data shouldn't be stored as a blob?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Blob Storage does not provide any mechanism for searching or sorting blobs by metadata\" this kind shouldnt be stored as blob.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Integrate data with Azure Data Factory or Azure Synapse Pipeline\n",
        "### Understand Azure Data Factory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which part of the symphony orchestra does Azure Data Factory play, according to the analogy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:\"To use an analogy, think about a symphony orchestra. The central member of the orchestra is the conductor. The conductor does not play the instruments, they simply lead the symphony members through the entire piece of music that they perform. The musicians use their own skills to produce particular sounds at various stages of the symphony, so they may only learn certain parts of the music. The conductor orchestrates the entire piece of music, and therefore is aware of the entire score that is being performed. They will also use specific arm movements that provide instructions to the musicians how a piece of music should be played.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Describe data integration patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What does ETL stand for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:  \"Extract, Transform and Load\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What does ELT stand for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Extract, load, and transform\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the difference between ETL and ELT?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \n",
        "\"Data integration firstly involves the collection of data from one or more sources. Optionally, it typically then includes a process where the data may be cleansed and transformed, or perhaps augmented with additional data and prepared. Finally, the amalgamated data is stored in a data platform service that handles the type of analytics that you want to perform. This process can be automated by Azure Data Factory in a pattern known as Extract, Transform and Load (ETL).\n",
        "\n",
        "and ELT stand for extract, load, transform where Azure has opened the way for technologies that can handle unstructured data at an unlimited scale. This change has shifted the paradigm for loading and transforming data from ETL to extract, load, and transform (ELT).\n",
        "\n",
        "The benefit of ELT is that you can store data in its original format, be it JSON, XML, PDF, or images. In ELT, you define the data's structure during the transformation phase, so you can use the source data in multiple downstream systems.\n",
        "\n",
        "In an ELT process, data is extracted and loaded in its native format. This change reduces the time required to load the data into a destination system. The change also limits resource contention on the data sources.\n",
        "\n",
        "The steps for the ELT process are the same as for the ETL process. They just follow a different order.\n",
        "\n",
        "Another process like ELT is called extract, load, transform, and load (ELTL). The difference with ELTL is that it has a final load into a destination system\" so that is the differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create Data Factory activities and pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which are the three categories of Azure Data factory activities?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Data movement activities, Data transformation activities, Control activities\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Large-scale data processing with Azure Data Lake Storage Gen2\n",
        "### Introduction to Azure Data Lake Storage Gen2\n",
        "#### Understand Azure Data Lake Storage Gen2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which format is data stored in in a data lake?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"A data lake is a repository of data that is stored in its natural format, usually as blobs or files. Azure Data Lake Storage is a comprehensive, massively scalable, secure, and cost-effective data lake solution for high performance analytics built into Azure\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ Which factors should influence the planning of a data lake?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \" Whenever planning for a data lake, a data engineer should give thoughtful consideration to structure, data governance, and security. This should include consideration of factors that can influence lake structure and organization, such as:\n",
        "\n",
        "Types of data to be stored\n",
        "How the data will be transformed\n",
        "Who should access the data\n",
        "What are the typical access patterns\n",
        "\n",
        "This approach will help determine how to plan for access control governance across your lake. Data engineers should be proactive in ensuring that the lake doesn't become the proverbial data swamp which becomes inaccessible and non-useful to users due to the lack of data governance and data quality measures. Establishing a baseline and following best practices for Azure Data Lake will help ensure a proper and robust implementation that will allow the organization to grow and gain insight to achieve more\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Enable Azure Data Lake storage Gen2 in Azure Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the name of the option that enables Azure Data Lake Storage Gen2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"To enable Azure Data Lake Storage Gen2 in an Azure Storage account, you can select the option to Enable hierarchical namespace in the Advanced page when creating the storage account in the Azure portalAzure Data Lake Storage combines a file system with a storage platform to help you quickly identify insights into your data. Data Lake Storage builds on Azure Blob storage capabilities to optimize it specifically for analytics workloads. This integration enables analytics performance, the tiering and data lifecycle management capabilities of Blob storage, and the high-availability, security, and durability capabilities of Azure Storage\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compare Azure Data Lake Storage and Azure Blob storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What is the main difference between Azure Data Lake Storage and Azure Blob storage?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer:  \" In Azure Blob storage, you can store large amounts of unstructured (\"object\") data in a flat namespace within a blob container. Blob names can include \"/\" characters to organize blobs into virtual \"folders\", but in terms of blob manageability the blobs are stored as a single-level hierarchy in a flat namespace. And in  Azure Data Lake Storage Gen2 builds on blob storage and optimizes I/O of high-volume data by using a hierarchical namespace that organizes blob data into directories, and stores metadata about each directory and the files within it. This structure allows operations, such as directory renames and deletes, to be performed in a single atomic operation. Flat namespaces, by contrast, require several operations proportionate to the number of objects in the structure. Hierarchical namespaces keep the data organized, which yields better storage and retrieval performance for an analytical use case and lowers the cost of analysis\". That the difference in both.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of storage account should you use to store website assets such as images and videos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"If you want to store data without performing analysis on the data, set the Hierarchical Namespace option to Disabled to set up the storage account as an Azure Blob storage account. You can also use blob storage to archive rarely used data or to store website assets such as images and media\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What kind of storage account should you use to store data that you wih to perform analytics on?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"If you are performing analytics on the data, set up the storage account as an Azure Data Lake Storage Gen2 account by setting the Hierarchical Namespace option to Enabled. Because Azure Data Lake Storage Gen2 is integrated into the Azure Storage platform, applications can use either the Blob APIs or the Azure Data Lake Storage Gen2 file system APIs to access data\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Use Azure Data Lake Storage Gen2 in data analytics workloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "❓ What are the three \"v's\" that are involved when processing big data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✔️ Answer: \"Azure Data Lake Store Gen2 is an enabling technology for multiple data analytics use cases. Let's explore a few common types of analytical workload, and identify how Azure Data Lake Storage Gen2 works with other Azure services to support them.\n",
        "Big data scenarios usually refer to analytical workloads that involve massive volumes of data in a variety of formats that needs to be processed at a fast velocity - the so-called \"three v's\". Azure Data Lake Storage Gen 2 provides a scalable and secure distributed data store on which big data services such as Azure Synapse Analytics, Azure Databricks, and Azure HDInsight can apply data processing frameworks such as Apache Spark, Hive, and Hadoop. The distributed nature of the storage and the processing compute enables tasks to be performed in parallel, resulting in high-performance and scalability even when processing huge amounts of data\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "källa \n",
        "\n",
        "https://learn.microsoft.com/en-us/collections/3140s6twkorq6z?sharingId=A70F2DF98827F6CC"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3",
      "path": "/home/linus/.local/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
